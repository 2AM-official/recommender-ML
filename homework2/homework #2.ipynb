{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSE 258 - HOMEWORK 2\n",
    "#### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import essential package\n",
    "import gzip\n",
    "import math\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data and put into dataset[]\n",
    "dataset = []\n",
    "path = \"goodreads_reviews_comics_graphic.json.gz\"\n",
    "with gzip.open(path, 'rt', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        dataset.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task1 - Similarity Functions\n",
    "### Question1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerItem = defaultdict(set) # Maps an item to the users who rated it\n",
    "itemsPerUser = defaultdict(set) # Maps a user to the items that they rated\n",
    "ratingDict = {} # To retrieve a rating for a specific user/item pair\n",
    "\n",
    "for d in dataset:\n",
    "    user,item = d['user_id'], d['book_id']\n",
    "    usersPerItem[item].add(user)\n",
    "    itemsPerUser[user].add(item)\n",
    "    ratingDict[(user,item)] = d['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity metrics of Jaccard similarity\n",
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilar(i, N):\n",
    "    similarities = []\n",
    "    users = usersPerItem[i]\n",
    "    for i2 in usersPerItem:\n",
    "        if i2 == i: continue\n",
    "        sim = Jaccard(users, usersPerItem[i2])\n",
    "        similarities.append((sim,i2))\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = dataset[0]['book_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 1 Answer: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.16666666666666666, '25334626'),\n",
       " (0.14285714285714285, '25659811'),\n",
       " (0.13793103448275862, '18369278'),\n",
       " (0.13157894736842105, '18430205'),\n",
       " (0.12903225806451613, '20299669'),\n",
       " (0.125, '17995154'),\n",
       " (0.12121212121212122, '23241671'),\n",
       " (0.12121212121212122, '23093378'),\n",
       " (0.12121212121212122, '18853527'),\n",
       " (0.11764705882352941, '26778333')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms = mostSimilar(query, 10)\n",
    "print(\"\\nQuestion 1 Answer: \")\n",
    "ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "userID = 'dc3763cdb9b2cae805882878eebb6a32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def favorite(userID):\n",
    "    user = itemsPerUser[userID]\n",
    "    itemRate = [x for x in zip(user, [ratingDict[(userID, rate)] for rate in user])]\n",
    "    itemRate = sorted(itemRate, key = lambda x: x[0])\n",
    "    itemRate = sorted(itemRate, key = lambda x: x[1], reverse = True)\n",
    "    return itemRate[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 2(a) Answer: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.16666666666666666, '25334626'),\n",
       " (0.14285714285714285, '25659811'),\n",
       " (0.13793103448275862, '18369278'),\n",
       " (0.13157894736842105, '18430205'),\n",
       " (0.12903225806451613, '20299669'),\n",
       " (0.125, '17995154'),\n",
       " (0.12121212121212122, '23241671'),\n",
       " (0.12121212121212122, '23093378'),\n",
       " (0.12121212121212122, '18853527'),\n",
       " (0.11764705882352941, '26778333')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "favoriteItem = favorite(userID)\n",
    "similarItem = mostSimilar(favoriteItem, 10)\n",
    "print(\"\\nQuestion 2(a) Answer: \")\n",
    "similarItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = dataset[0]['book_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilarUser(i, N):\n",
    "    similarities = []\n",
    "    items = itemsPerUser[i]\n",
    "    for i2 in itemsPerUser:\n",
    "        if i2 == i: continue\n",
    "        sim = Jaccard(items, itemsPerUser[i2])\n",
    "        #sim = Pearson(i, i2) # Could use alternate similarity metrics straightforwardly\n",
    "        similarities.append((sim,i2))\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = mostSimilarUser(userID, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findOtherFavor(similarities, N):\n",
    "    favoriteOtherItems = []\n",
    "    for a in similarities:\n",
    "        bookID = favorite(a[1])\n",
    "        if bookID == favoriteItem : continue\n",
    "        favoriteOtherItems.append((a[0], a[1], bookID))\n",
    "    return favoriteOtherItems[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 2(b) Answer: Associated Scores, User ID, Recommend Book ID\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.3333333333333333, '6470c7f5e3468ba34e9fe628960fbbf1', '10767466'),\n",
       " (0.25, '6497ca91df3c182006874c96a8530b37', '17570797'),\n",
       " (0.2, '033cf640dfa6f85eb146c39787289628', '15704307'),\n",
       " (0.14285714285714285, '5510684ab6c18f2dd493787e66b2722c', '10138607'),\n",
       " (0.05555555555555555, '17f73ea38e97307935c0d3b6ca987b53', '12434747'),\n",
       " (0.030303030303030304, 'a39b4249d201ef5ce5ea553bdd013e66', '17995248'),\n",
       " (0.023809523809523808, '42519f961f79b61701bda60787b031cf', '10105459'),\n",
       " (0.02040816326530612, '65a7975989734fc6e18b7d2bd2bcb49f', '10997645'),\n",
       " (0.014925373134328358, '0fafb6f0843124383f4e2c5a2090fb09', '10361139'),\n",
       " (0.0136986301369863, '071222e19ae29dc9fdbe225d983449be', '10264328')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nQuestion 2(b) Answer: Associated Scores, User ID, Recommend Book ID\")\n",
    "findOtherFavor(similarities, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "userAverages = {}\n",
    "itemAverages = {}\n",
    "\n",
    "for u in itemsPerUser:\n",
    "    rs = [ratingDict[(u,i)] for i in itemsPerUser[u]]\n",
    "    userAverages[u] = sum(rs) / len(rs)\n",
    "    \n",
    "for i in usersPerItem:\n",
    "    rs = [ratingDict[(u,i)] for u in usersPerItem[i]]\n",
    "    itemAverages[i] = sum(rs) / len(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pearson(i1, i2):\n",
    "    # Between two items\n",
    "    iBar1 = itemAverages[i1]\n",
    "    iBar2 = itemAverages[i2]\n",
    "    inter = usersPerItem[i1].intersection(usersPerItem[i2])\n",
    "    numer = 0\n",
    "    denom1 = 0\n",
    "    denom2 = 0\n",
    "    for u in inter:\n",
    "        numer += (ratingDict[(u,i1)] - iBar1)*(ratingDict[(u,i2)] - iBar2)\n",
    "    for u in inter: #usersPerItem[i1]:\n",
    "        denom1 += (ratingDict[(u,i1)] - iBar1)**2\n",
    "    #for u in usersPerItem[i2]:\n",
    "        denom2 += (ratingDict[(u,i2)] - iBar2)**2\n",
    "    denom = math.sqrt(denom1) * math.sqrt(denom2)\n",
    "    if denom == 0: return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilar(i, N):\n",
    "    similarities = []\n",
    "    users = usersPerItem[i]\n",
    "    for i2 in usersPerItem:\n",
    "        if i2 == i: continue\n",
    "        sim = Pearson(i, i2) # Could use alternate similarity metrics straightforwardly\n",
    "        similarities.append((sim,i2))\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 3.1 Answer: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1.0000000000000002, '993861'),\n",
       " (1.0000000000000002, '7986827'),\n",
       " (1.0000000000000002, '7342071'),\n",
       " (1.0000000000000002, '62953'),\n",
       " (1.0000000000000002, '33585240'),\n",
       " (1.0000000000000002, '3328828'),\n",
       " (1.0000000000000002, '31855855'),\n",
       " (1.0000000000000002, '31224404'),\n",
       " (1.0000000000000002, '30272308'),\n",
       " (1.0000000000000002, '29840108')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = dataset[0]['book_id']\n",
    "ms = mostSimilar(query, 10)\n",
    "print(\"\\nQuestion 3.1 Answer: \")\n",
    "ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pearson(i1, i2):\n",
    "    # Between two items\n",
    "    iBar1 = itemAverages[i1]\n",
    "    iBar2 = itemAverages[i2]\n",
    "    inter = usersPerItem[i1].intersection(usersPerItem[i2])\n",
    "    numer = 0\n",
    "    denom1 = 0\n",
    "    denom2 = 0\n",
    "    for u in inter:\n",
    "        numer += (ratingDict[(u,i1)] - iBar1)*(ratingDict[(u,i2)] - iBar2)\n",
    "    for u in usersPerItem[i1]:\n",
    "        denom1 += (ratingDict[(u,i1)] - iBar1)**2\n",
    "    for u in usersPerItem[i2]:\n",
    "        denom2 += (ratingDict[(u,i2)] - iBar2)**2\n",
    "    denom = math.sqrt(denom1) * math.sqrt(denom2)\n",
    "    if denom == 0: return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 3.2 Answer: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.31898549007874194, '20300526'),\n",
       " (0.18785865431369264, '13280885'),\n",
       " (0.17896391275176457, '18208501'),\n",
       " (0.16269036695641687, '25430791'),\n",
       " (0.16269036695641687, '21521612'),\n",
       " (0.1555075595594449, '1341758'),\n",
       " (0.1526351566298752, '6314737'),\n",
       " (0.15204888048160353, '4009034'),\n",
       " (0.1494406444160154, '988744'),\n",
       " (0.1463241948128199, '18430205')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = dataset[0]['book_id']\n",
    "ms = mostSimilar(query, 10)\n",
    "print(\"\\nQuestion 3.2 Answer: \")\n",
    "ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Rating Prediction\n",
    "#### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataset:\n",
    "    user,item = d['user_id'], d['book_id']\n",
    "    reviewsPerUser[user].append(d)\n",
    "    reviewsPerItem[item].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingMean = sum([d['rating'] for d in dataset]) / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictRating(user,item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for d in reviewsPerUser[user]:\n",
    "        i2 = d['book_id']\n",
    "        if i2 == item: continue\n",
    "        ratings.append(d['rating'] - itemAverages[i2])\n",
    "        similarities.append(Jaccard(usersPerItem[item],usersPerItem[i2]))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return itemAverages[item] + sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        return itemAverages[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "alwaysPredictMean = [ratingMean for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "simPredictions = [predictRating(d['user_id'], d['book_id']) for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [d['rating'] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 4 Answer: \n",
      "MSE:  0.7017041185560355\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nQuestion 4 Answer: \")\n",
    "print(\"MSE: \", MSE(simPredictions, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 6 Answer: \n",
      "MSE:  0.6975936563299326\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import dateutil.parser\n",
    "\n",
    "def predictRating(user, item, timestamp):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for d in reviewsPerUser[user]:\n",
    "        timestamp2 = dateutil.parser.parse(d['date_added']).timestamp()\n",
    "        diff = abs(timestamp2 - timestamp) / 86400\n",
    "        parameter = 0.0022\n",
    "        ft = math.exp(-diff * parameter)\n",
    "        i2 = d['book_id']\n",
    "        if i2 == item: continue\n",
    "        ratings.append(d['rating'] - itemAverages[i2])\n",
    "        similarities.append(Jaccard(usersPerItem[item], usersPerItem[i2])*ft)\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return itemAverages[item] + sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        return itemAverages[item]\n",
    "    \n",
    "time = dateutil.parser.parse(dataset[0]['date_added'])\n",
    "dateParsed = [dateutil.parser.parse(d['date_added']).timestamp() for d in dataset]\n",
    "labels = [d['rating'] for d in dataset]\n",
    "simPredictions = [predictRating(d['user_id'], d['book_id'], dateutil.parser.parse(d['date_added']).timestamp()) for d in dataset]\n",
    "\n",
    "print(\"\\nQuestion 6 Answer: \")\n",
    "print(\"MSE: \", MSE(simPredictions, labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Wintertime",
   "language": "python",
   "name": "wintertime"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
